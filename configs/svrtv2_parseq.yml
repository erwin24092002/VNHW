Global:
  device: gpu
  epoch_num: 500
  log_smooth_window: 50
  print_batch_step: 100
  output_dir: outputs/svtrv2_parseq
  eval_epoch_step: [0, 1]
  eval_batch_step: [0, 500]
  save_epoch_step: [15, 9999]
  cal_metric_during_train: False
  pretrained_model: outputs/svtrv2_parseq/best.pth
  checkpoints: 
  use_tensorboard: False
  infer_img: data/data_raw/UIT_HWDB_word/train_data/1
  # for data or label process
  character_dict_path: &character_dict_path data/character_dict/uit_hwdb_word.txt
  max_text_length: &max_text_length 15
  use_space_char: &use_space_char False
  use_amp: True
  save_res_path: outputs/svtrv2_parseq/predicts_svtrv2_parseq.txt

Optimizer:
  name: AdamW
  lr: 0.00003 #0.00065 # 4gpus 256bs/gpu
  weight_decay: 0.05
  filter_bias_and_bn: False

LRScheduler:
  name: OneCycleLR
  warmup_epoch: 5 # pct_start 0.075*20 = 1.5ep
  cycle_momentum: False

Architecture:
  model_type: rec
  algorithm: PARSeq
  Transform:
  Encoder:
    name: SVTRv2LNConvTwo33
    use_pos_embed: False
    dims: [128, 256, 384]
    depths: [6, 6, 6]
    num_heads: [4, 8, 12]
    mixer: [['Conv','Conv','Conv','Conv','Conv','Conv'],['Conv','Conv','FGlobal','Global','Global','Global'],['Global','Global','Global','Global','Global','Global']]
    local_k: [[5, 5], [5, 5], [-1, -1]]
    sub_k: [[1, 1], [2, 1], [-1, -1]]
    last_stage: False
  Decoder:
    name: PARSeqDecoder
    decode_ar: True
    refine_iters: 0
    only_attn: False

Loss:
  name: PARSeqLoss

PostProcess:
  name: ARLabelDecode
  character_dict_path: *character_dict_path
  use_space_char: *use_space_char

Metric:
  name: RecMetric
  main_indicator: acc
  is_filter: False

Train:
  dataset:
    name: RatioDataSetTVResize
    ds_width: True
    padding: False
    data_dir_list: [
      data/data_lmdb/train,
    ]
    transforms:
      - DecodeImagePIL: # load image
          img_mode: RGB
      # - PARSeqAugPIL:
      - ARLabelEncode: # Class handling label
          character_dict_path: *character_dict_path
          use_space_char: *use_space_char
          max_text_length: *max_text_length
      - KeepKeys:
          keep_keys: ['image', 'label', 'length'] # dataloader will return list in this order
  sampler:
    name: RatioSampler
    scales: [[192, 64]] # w, h
    # divide_factor: to ensure the width and height dimensions can be devided by downsampling multiple
    first_bs: &bs 130
    fix_bs: false
    divided_factor: [4, 16] # w, h
    is_training: True
  loader:
    shuffle: True
    batch_size_per_card: *bs
    drop_last: True
    max_ratio: &max_ratio 4
    num_workers: 4

Eval:
  dataset:
    name: RatioDataSetTVResize
    ds_width: True
    padding: False
    data_dir_list: [
      data/data_lmdb/test,
    ]
    transforms:
      - DecodeImagePIL: # load image
          img_mode: RGB
      - ARLabelEncode: # Class handling label
          character_dict_path: *character_dict_path
          use_space_char: *use_space_char
          max_text_length: *max_text_length
      - KeepKeys:
          keep_keys: ['image', 'label', 'length'] # dataloader will return list in this order
  sampler:
    name: RatioSampler
    scales: [[192, 64]] # w, h
    # divide_factor: to ensure the width and height dimensions can be devided by downsampling multiple
    first_bs: *bs
    fix_bs: false
    divided_factor: [4, 16] # w, h
    is_training: False
  loader:
    shuffle: False
    drop_last: False
    batch_size_per_card: *bs
    max_ratio: *max_ratio
    num_workers: 4
